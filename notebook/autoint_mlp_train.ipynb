{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a34c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\ds6_rcmm\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, MaxPooling2D, Conv2D, Dropout, Lambda, Dense, Flatten, Activation, Input, Embedding, BatchNormalization\n",
    "from tensorflow.keras.initializers import glorot_normal, Zeros, TruncatedNormal\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5841053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesEmbedding(Layer):  \n",
    "    '''\n",
    "    임베딩 레이어입니다. \n",
    "    - 만약 피처(feature) 3개가 각각 10개, 20개, 30개의 고유값을 가진다면 feature_dims는 [10, 20, 30] 형태를 띄게 됩니다.\n",
    "    - 전체 임베딩을 해야 할 개수는 10+20+30 = 60이므로 '60 x 임베딩_차원_크기'의 행렬이 생성되게 됩니다.\n",
    "    '''\n",
    "    def __init__(self, field_dims, embed_dim, **kwargs):\n",
    "        super(FeaturesEmbedding, self).__init__(**kwargs)\n",
    "        self.total_dim = sum(field_dims)\n",
    "        self.embed_dim = embed_dim\n",
    "        ## int 64로 바꿔주자\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.int64)\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.total_dim, output_dim=self.embed_dim)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # 임베딩을 빌드하고 초기화합니다.\n",
    "        self.embedding.build(input_shape)\n",
    "        self.embedding.set_weights([tf.keras.initializers.GlorotUniform()(shape=self.embedding.weights[0].shape)])\n",
    "\n",
    "    def call(self, x):\n",
    "        # 들어온 입력의 임베딩을 가져니다.\n",
    "        x = x + tf.constant(self.offsets)\n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d43c673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(Layer):  \n",
    "    '''\n",
    "    DNN 레이어입니다.\n",
    "    - Tensorflow Keras에서는 Dense 레이어를 쌓아올린 구조입니다.\n",
    "    - 필요에 따라 배치 정규화도 사용할 수 있습니다.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_units, activation='relu', l2_reg=0, dropout_rate=0, use_bn=False, init_std=0.0001, output_layer=True):\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_bn = use_bn\n",
    "        hidden_units = [input_dim] + list(hidden_units)\n",
    "        if output_layer:\n",
    "            hidden_units += [1]\n",
    "        # Dense layer를 쌓아올립니다.\n",
    "        self.linears = [Dense(units, activation=None, kernel_initializer=tf.random_normal_initializer(stddev=init_std),\n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(l2_reg)) for units in hidden_units[1:]]\n",
    "        # 활성화 함수를 세팅합니다.\n",
    "        self.activation = tf.keras.layers.Activation(activation)\n",
    "        # 필요하다면 배치정규화도 진행합니다.\n",
    "        if self.use_bn:\n",
    "            self.bn = [BatchNormalization() for _ in hidden_units[1:]]\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = inputs\n",
    "        for i in range(len(self.linears)):\n",
    "            # input data가 들어오면 layer를 돌면서 벡터 값을 가져오게 됩니다.\n",
    "            x = self.linears[i](x)\n",
    "            if self.use_bn:\n",
    "                x = self.bn[i](x, training=training)\n",
    "            # 각 layer마다 나온 벡터 값에 활성화 함수와 dropout을 적용시켜 비선형성 구조와 과적합을 방지합니다.\n",
    "            x = self.activation(x)\n",
    "            x = self.dropout(x, training=training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b87f2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer):  \n",
    "    '''\n",
    "    멀티 헤드 셀프 어텐션 레이어입니다.\n",
    "    - 위에 작성한 수식과 같이 동작됩니다.\n",
    "    - 필요에 따라 잔차 연결(residual connection)도 진행합니다.\n",
    "    '''\n",
    "    def __init__(self, att_embedding_size=8, head_num=2, use_res=True, scaling=False, seed=1024, **kwargs):\n",
    "        if head_num <= 0:\n",
    "            raise ValueError('head_num must be a int > 0')\n",
    "        self.att_embedding_size = att_embedding_size\n",
    "        self.head_num = head_num\n",
    "        self.use_res = use_res\n",
    "        self.seed = seed\n",
    "        self.scaling = scaling\n",
    "        super(MultiHeadSelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) != 3:\n",
    "            raise ValueError(\n",
    "                \"Unexpected inputs dimensions %d, expect to be 3 dimensions\" % (len(input_shape)))\n",
    "        embedding_size = int(input_shape[-1])\n",
    "        # 쿼리에 해당하는 매트릭스입니다. \n",
    "        self.W_Query = self.add_weight(name='query', shape=[embedding_size, self.att_embedding_size * self.head_num],\n",
    "                                       dtype=tf.float32,\n",
    "                                       initializer=TruncatedNormal(seed=self.seed))\n",
    "        # 키에 해당되는 매트릭스입니다.\n",
    "        self.W_key = self.add_weight(name='key', shape=[embedding_size, self.att_embedding_size * self.head_num],\n",
    "                                     dtype=tf.float32,\n",
    "                                     initializer=TruncatedNormal(seed=self.seed + 1))\n",
    "        # 값(value)에 해당되는 매트릭스입니다.\n",
    "        self.W_Value = self.add_weight(name='value', shape=[embedding_size, self.att_embedding_size * self.head_num],\n",
    "                                       dtype=tf.float32,\n",
    "                                       initializer=TruncatedNormal(seed=self.seed + 2))\n",
    "        # 필요하다면 잔차 연결도 할 수 있습니다.\n",
    "        if self.use_res:\n",
    "            self.W_Res = self.add_weight(name='res', shape=[embedding_size, self.att_embedding_size * self.head_num],\n",
    "                                         dtype=tf.float32,\n",
    "                                         initializer=TruncatedNormal(seed=self.seed))\n",
    "\n",
    "        super(MultiHeadSelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if K.ndim(inputs) != 3:\n",
    "            raise ValueError(\"Unexpected inputs dimensions %d, expect to be 3 dimensions\" % (K.ndim(inputs)))\n",
    "        \n",
    "        # 입력이 들어오면 쿼리, 키, 값(value)에 매칭되어 각각의 값을 가지고 옵니다.\n",
    "        querys = tf.tensordot(inputs, self.W_Query, axes=(-1, 0))  \n",
    "        keys = tf.tensordot(inputs, self.W_key, axes=(-1, 0))\n",
    "        values = tf.tensordot(inputs, self.W_Value, axes=(-1, 0))\n",
    "\n",
    "        # 헤드 개수에 따라 데이터를 분리해줍니다.\n",
    "        querys = tf.stack(tf.split(querys, self.head_num, axis=2))\n",
    "        keys = tf.stack(tf.split(keys, self.head_num, axis=2))\n",
    "        values = tf.stack(tf.split(values, self.head_num, axis=2))\n",
    "        \n",
    "        # 쿼리와 키를 먼저 곱해줍니다. 위 이미지의 식 (5)와 같습니다.\n",
    "        inner_product = tf.matmul(querys, keys, transpose_b=True)\n",
    "        if self.scaling:\n",
    "            inner_product /= self.att_embedding_size ** 0.5\n",
    "        self.normalized_att_scores =  tf.nn.softmax(inner_product)\n",
    "        \n",
    "        # 쿼리와 키에서 나온 어텐션 값을 값(value)에 곱해줍니다. 식 (6)과 같습니다.\n",
    "        result = tf.matmul(self.normalized_att_scores, values)\n",
    "        # 식 (7)과 같이 쪼개어진 멀테 헤드를 모아줍니다.\n",
    "        result = tf.concat(tf.split(result, self.head_num, ), axis=-1)\n",
    "        result = tf.squeeze(result, axis=0) \n",
    "\n",
    "        if self.use_res:\n",
    "            result += tf.tensordot(inputs, self.W_Res, axes=(-1, 0))\n",
    "        result = tf.nn.relu(result)\n",
    "        \n",
    "        # 그 결과 값을 리턴합니다.\n",
    "\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "\n",
    "        return (None, input_shape[1], self.att_embedding_size * self.head_num)\n",
    "\n",
    "    def get_config(self, ):\n",
    "        config = {'att_embedding_size': self.att_embedding_size, 'head_num': self.head_num, 'use_res': self.use_res,'seed': self.seed}\n",
    "        base_config = super(MultiHeadSelfAttention, self).get_config()\n",
    "        base_config.update(config)\n",
    "        return base_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3308662e",
   "metadata": {},
   "source": [
    "# 바꿀 부분\n",
    "\n",
    "이 밑에있는 모델 정의를 새로운 모델로 해주셔야합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf154a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoIntMLP(Layer): \n",
    "    def __init__(self, field_dims, embedding_size, att_layer_num=3, att_head_num=4, att_res=True, \n",
    "                 dnn_hidden_units=(256, 128, 64), dnn_activation='relu',\n",
    "                 l2_reg_dnn=1e-5, l2_reg_embedding=1e-5, dnn_use_bn=True, dnn_dropout=0.2, init_std=0.001):\n",
    "        super(AutoIntMLP, self).__init__()\n",
    "        self.embedding = FeaturesEmbedding(field_dims, embedding_size)\n",
    "        self.num_fields = len(field_dims)\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.dnn = tf.keras.Sequential()\n",
    "        for units in dnn_hidden_units:\n",
    "            self.dnn.add(Dense(units, kernel_initializer=tf.random_normal_initializer(stddev=init_std)))\n",
    "            if dnn_use_bn:\n",
    "                self.dnn.add(BatchNormalization())\n",
    "            self.dnn.add(Activation(dnn_activation))\n",
    "            if dnn_dropout > 0:\n",
    "                self.dnn.add(Dropout(dnn_dropout))\n",
    "        \n",
    "        self.int_layers = [MultiHeadSelfAttention(att_embedding_size=embedding_size, head_num=att_head_num, use_res=att_res) \n",
    "                           for _ in range(att_layer_num)]\n",
    "\n",
    "        # [중요] Concat 후 결과를 하나로 합치는 최종 출력층 (에러 해결의 핵심)\n",
    "        self.combine_dense = Dense(1, activation='sigmoid', kernel_initializer=tf.random_normal_initializer(stddev=init_std))\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        embed_x = self.embedding(inputs)\n",
    "        \n",
    "        # 1. Attention 경로\n",
    "        att_input = embed_x\n",
    "        for layer in self.int_layers:\n",
    "            att_input = layer(att_input)\n",
    "        att_output = Flatten()(att_input)\n",
    "\n",
    "        # 2. DNN 경로\n",
    "        dnn_embed = tf.reshape(embed_x, shape=(-1, self.embedding_size * self.num_fields))\n",
    "        dnn_output = self.dnn(dnn_embed, training=training)\n",
    "\n",
    "        # 3. [개선] 더하기 대신 연결(Concat) 방식 적용\n",
    "        combined = tf.concat([att_output, dnn_output], axis=-1)\n",
    "        \n",
    "        return self.combine_dense(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f0752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DCG(ranklist, y_true):\n",
    "    dcg = 0.0\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item in y_true:\n",
    "            dcg += 1.0 / math.log(i + 2)\n",
    "    return  dcg\n",
    "\n",
    "def get_IDCG(ranklist, y_true):\n",
    "    idcg = 0.0\n",
    "    i = 0\n",
    "    for item in y_true:\n",
    "        if item in ranklist:\n",
    "            idcg += 1.0 / math.log(i + 2)\n",
    "            i += 1\n",
    "    return idcg\n",
    "\n",
    "def get_NDCG(ranklist, y_true):\n",
    "    '''NDCG 평가 지표'''\n",
    "    ranklist = np.array(ranklist).astype(int)\n",
    "    y_true = np.array(y_true).astype(int)\n",
    "    dcg = get_DCG(ranklist, y_true)\n",
    "    idcg = get_IDCG(y_true, y_true)\n",
    "    if idcg == 0:\n",
    "        return 0\n",
    "    return round( (dcg / idcg), 5)\n",
    "\n",
    "def get_hit_rate(ranklist, y_true):\n",
    "    '''hitrate 평가 지표'''\n",
    "    c = 0\n",
    "    for y in y_true:\n",
    "        if y in ranklist:\n",
    "            c += 1\n",
    "    return round( c / len(y_true), 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be89da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_df):\n",
    "    '''모델 테스트'''\n",
    "    user_pred_info = defaultdict(list)\n",
    "    total_rows = len(test_df)\n",
    "    \n",
    "    # 배치 사이즈가 정의되어 있지 않을 경우를 대비해 기본값 설정 (필요시 수정)\n",
    "    # batch_size = 256 \n",
    "    \n",
    "    for i in range(0, total_rows, batch_size):\n",
    "        # 정답(label) 열을 제외한 피처 추출\n",
    "        features = test_df.iloc[i:i + batch_size, :-1].values\n",
    "        y_pred = model.predict(features, verbose=False)\n",
    "        \n",
    "        for feature, p in zip(features, y_pred):\n",
    "            # feature[:2]는 [user_id, movie_id] 형태의 배열입니다.\n",
    "            u_i = feature[:2]\n",
    "            \n",
    "            # .item()을 사용하여 numpy array 내부의 값을 순수 파이썬 숫자로 추출합니다.\n",
    "            u_id = int(u_i[0].item())\n",
    "            m_id = int(u_i[1].item())\n",
    "            \n",
    "            # 예측 확률 값 p도 단일 숫자로 변환합니다.\n",
    "            pred_score = float(p.item() if hasattr(p, 'item') else p)\n",
    "            \n",
    "            user_pred_info[u_id].append((m_id, pred_score))\n",
    "            \n",
    "    return user_pred_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e81ad2",
   "metadata": {},
   "source": [
    "# 학습용 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86119a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = os.path.abspath(os.getcwd())\n",
    "data_dir_nm = 'data'\n",
    "movielens_dir_nm = 'ml-1m'\n",
    "model_dir_nm = 'model'\n",
    "data_path = f\"{project_path}/{data_dir_nm}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "862ceeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000209, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_decade</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>rating_year</th>\n",
       "      <th>rating_month</th>\n",
       "      <th>rating_decade</th>\n",
       "      <th>genre1</th>\n",
       "      <th>genre2</th>\n",
       "      <th>genre3</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>1970s</td>\n",
       "      <td>1975</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>1990s</td>\n",
       "      <td>1996</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000s</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Musical</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>1960s</td>\n",
       "      <td>1964</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000s</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Romance</td>\n",
       "      <td>no</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>2000s</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>1990s</td>\n",
       "      <td>1998</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>2000s</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id movie_id movie_decade movie_year rating_year rating_month  \\\n",
       "0       1     1193        1970s       1975        2000           12   \n",
       "1       1      661        1990s       1996        2000           12   \n",
       "2       1      914        1960s       1964        2000           12   \n",
       "3       1     3408        2000s       2000        2000           12   \n",
       "4       1     2355        1990s       1998        2001            1   \n",
       "\n",
       "  rating_decade     genre1      genre2   genre3 gender age occupation    zip  \\\n",
       "0         2000s      Drama          no       no      F   1         10  48067   \n",
       "1         2000s  Animation  Children's  Musical      F   1         10  48067   \n",
       "2         2000s    Musical     Romance       no      F   1         10  48067   \n",
       "3         2000s      Drama          no       no      F   1         10  48067   \n",
       "4         2000s  Animation  Children's   Comedy      F   1         10  48067   \n",
       "\n",
       "  label  \n",
       "0     1  \n",
       "1     0  \n",
       "2     0  \n",
       "3     1  \n",
       "4     1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 데이터 불러오기\n",
    "# csv 데이터이므로 read_csv로 가져옵니다.\n",
    "movielens_rcmm = pd.read_csv(\"C:\\\\Users\\\\Admin\\\\autoint\\\\data\\\\movielens_rcmm_v2.csv\", dtype=str)\n",
    "print(movielens_rcmm.shape)\n",
    "movielens_rcmm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a71be7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {col: LabelEncoder() for col in movielens_rcmm.columns[:-1]} # label은 제외\n",
    "\n",
    "for col, le in label_encoders.items():\n",
    "    movielens_rcmm[col] = le.fit_transform(movielens_rcmm[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f83532a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_decade</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>rating_year</th>\n",
       "      <th>rating_month</th>\n",
       "      <th>rating_decade</th>\n",
       "      <th>genre1</th>\n",
       "      <th>genre2</th>\n",
       "      <th>genre3</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3374</td>\n",
       "      <td>8</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3615</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2503</td>\n",
       "      <td>9</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1374</td>\n",
       "      <td>8</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  movie_decade  movie_year  rating_year  rating_month  \\\n",
       "0        0       189             6          55            0             3   \n",
       "1        0      3374             8          76            0             3   \n",
       "2        0      3615             5          44            0             3   \n",
       "3        0      2503             9          80            0             3   \n",
       "4        0      1374             8          78            1             0   \n",
       "\n",
       "   rating_decade  genre1  genre2  genre3  gender  age  occupation   zip label  \n",
       "0              0       7      17      15       0    0           2  1588     1  \n",
       "1              0       2       2       8       0    0           2  1588     0  \n",
       "2              0      11      12      15       0    0           2  1588     0  \n",
       "3              0       7      17      15       0    0           2  1588     1  \n",
       "4              0       2       2       2       0    0           2  1588     1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movielens_rcmm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85089daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens_rcmm['label'] = movielens_rcmm['label'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8600c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 학습 데이터와 테스트데이터로 분리, 0.2 정도로 분리\n",
    "train_df, test_df = train_test_split(movielens_rcmm, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aa6bb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 800167 entries, 416292 to 121958\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   user_id        800167 non-null  int64  \n",
      " 1   movie_id       800167 non-null  int64  \n",
      " 2   movie_decade   800167 non-null  int64  \n",
      " 3   movie_year     800167 non-null  int64  \n",
      " 4   rating_year    800167 non-null  int64  \n",
      " 5   rating_month   800167 non-null  int64  \n",
      " 6   rating_decade  800167 non-null  int64  \n",
      " 7   genre1         800167 non-null  int64  \n",
      " 8   genre2         800167 non-null  int64  \n",
      " 9   genre3         800167 non-null  int64  \n",
      " 10  gender         800167 non-null  int64  \n",
      " 11  age            800167 non-null  int64  \n",
      " 12  occupation     800167 non-null  int64  \n",
      " 13  zip            800167 non-null  int64  \n",
      " 14  label          800167 non-null  float32\n",
      "dtypes: float32(1), int64(14)\n",
      "memory usage: 94.6 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45750737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6040, 3706,   10,   81,    4,   12,    1,   18,   18,   16,    2,\n",
       "          7,   21, 3439])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요 컬럼들과 레이블 정의\n",
    "# 필드의 각 고유 개수를 정의하는 field_dims를 정의합니다. 이는  임베딩 때 활용됩니다. \n",
    "u_i_feature = ['user_id', 'movie_id']\n",
    "meta_features = ['movie_decade', 'movie_year', 'rating_year', 'rating_month', 'rating_decade', 'genre1','genre2', 'genre3', 'gender', 'age', 'occupation', 'zip']\n",
    "label = 'label'\n",
    "field_dims = np.max(movielens_rcmm[u_i_feature + meta_features].astype(np.int64).values, axis=0) + 1\n",
    "field_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6196057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 에포크, 학습률, 드롭아웃, 배치사이즈, 임베딩 크기 등 정의\n",
    "# epochs=5\n",
    "# learning_rate= 0.0001\n",
    "# dropout= 0.4\n",
    "# batch_size = 2048\n",
    "# embed_dim= 16\n",
    "\n",
    "# [변경 추천] 고성능을 위한 설정값\n",
    "epochs = 10              # [변경] 5 -> 10 (조금 더 충분히 학습)\n",
    "learning_rate = 0.001    # [변경] 0.0001 -> 0.001 (학습 속도 최적화)\n",
    "dropout = 0.2            # [변경] 0.4 -> 0.2 (정보 손실을 줄임)\n",
    "batch_size = 1024        # [변경] 2048 -> 1024 (더 세밀하게 가중치 업데이트)\n",
    "embed_dim = 32           # [변경] 16 -> 32 (데이터의 특징을 더 풍부하게 담음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4fc038",
   "metadata": {},
   "source": [
    "# 고칠부분\n",
    "\n",
    "이부분도 AutoIntMLP를 가져와주고 DNN 레이어가 붙은 파라미터를 추가해줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "903cda8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AutoIntMLPModel(Model):\n",
    "    def __init__(self, field_dims, embedding_size, att_layer_num=3, att_head_num=2,\n",
    "                 att_res=True, dnn_hidden_units=(32, 32), dnn_activation='relu',\n",
    "                 l2_reg_dnn=0, l2_reg_embedding=1e-5, dnn_use_bn=False,\n",
    "                 dnn_dropout=0.4, init_std=0.0001):\n",
    "        super(AutoIntMLPModel, self).__init__()\n",
    "        self.autoInt_layer = AutoIntMLP(\n",
    "            field_dims=field_dims,\n",
    "            embedding_size=embedding_size,\n",
    "            att_layer_num=att_layer_num,\n",
    "            att_head_num=att_head_num,\n",
    "            att_res=att_res,\n",
    "            dnn_hidden_units=dnn_hidden_units,\n",
    "            dnn_activation=dnn_activation,\n",
    "            l2_reg_dnn=l2_reg_dnn,\n",
    "            l2_reg_embedding=l2_reg_embedding,\n",
    "            dnn_use_bn=dnn_use_bn,\n",
    "            dnn_dropout=dnn_dropout,\n",
    "            init_std=init_std\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        return self.autoInt_layer(inputs, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaad3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 정의\n",
    "# autoIntMLP_model = AutoIntMLPModel(\n",
    "#     field_dims=field_dims,\n",
    "#     embedding_size=embed_dim,\n",
    "#     att_layer_num=3,\n",
    "#     att_head_num=2,\n",
    "#     att_res=True,\n",
    "#     dnn_hidden_units=(32, 32),               # 추가: DNN 은닉층 구조\n",
    "#     dnn_activation='relu',                  # 추가: 활성화 함수\n",
    "#     l2_reg_dnn=0,\n",
    "#     l2_reg_embedding=1e-5,\n",
    "#     dnn_use_bn=False,\n",
    "#     dnn_dropout=dropout,\n",
    "#     init_std=0.0001\n",
    "# )\n",
    "\n",
    "# [수정 버전] 고성능 파라미터 적용\n",
    "autoIntMLP_model = AutoIntMLPModel(\n",
    "    field_dims=field_dims,\n",
    "    embedding_size=32,               # [변경] 16(또는 기존값) -> 32\n",
    "    att_layer_num=3,\n",
    "    att_head_num=4,                  # [변경] 2 -> 4 (헤드 수 증가)\n",
    "    att_res=True,\n",
    "    dnn_hidden_units=(256, 128, 64), # [변경] (32, 32) -> (256, 128, 64)\n",
    "    dnn_activation='relu',\n",
    "    l2_reg_dnn=1e-5,                 # [변경] 0 -> 1e-5 (과적합 방지)\n",
    "    l2_reg_embedding=1e-5,\n",
    "    dnn_use_bn=True,                 # [변경] False -> True (학습 안정화)\n",
    "    dnn_dropout=0.2,                 # [변경] 기존값 -> 0.2\n",
    "    init_std=0.001                   # [변경] 0.0001 -> 0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb4a2fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저, 오차함수 정의\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "loss_fn = BinaryCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "703ef842",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoIntMLP_model.compile(optimizer=optimizer, loss=loss_fn, metrics=['binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8a43379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 190ms/step - binary_crossentropy: 0.5621 - loss: 0.5621 - val_binary_crossentropy: 0.5393 - val_loss: 0.5393\n",
      "Epoch 2/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 171ms/step - binary_crossentropy: 0.5285 - loss: 0.5285 - val_binary_crossentropy: 0.5298 - val_loss: 0.5298\n",
      "Epoch 3/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 147ms/step - binary_crossentropy: 0.5147 - loss: 0.5147 - val_binary_crossentropy: 0.5240 - val_loss: 0.5240\n",
      "Epoch 4/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 163ms/step - binary_crossentropy: 0.5020 - loss: 0.5020 - val_binary_crossentropy: 0.5195 - val_loss: 0.5195\n",
      "Epoch 5/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 188ms/step - binary_crossentropy: 0.4918 - loss: 0.4918 - val_binary_crossentropy: 0.5195 - val_loss: 0.5195\n",
      "Epoch 6/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 162ms/step - binary_crossentropy: 0.4826 - loss: 0.4826 - val_binary_crossentropy: 0.5171 - val_loss: 0.5171\n",
      "Epoch 7/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 145ms/step - binary_crossentropy: 0.4740 - loss: 0.4740 - val_binary_crossentropy: 0.5210 - val_loss: 0.5210\n",
      "Epoch 8/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 212ms/step - binary_crossentropy: 0.4653 - loss: 0.4653 - val_binary_crossentropy: 0.5250 - val_loss: 0.5250\n",
      "Epoch 9/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 210ms/step - binary_crossentropy: 0.4570 - loss: 0.4570 - val_binary_crossentropy: 0.5258 - val_loss: 0.5258\n",
      "Epoch 10/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 184ms/step - binary_crossentropy: 0.4479 - loss: 0.4479 - val_binary_crossentropy: 0.5308 - val_loss: 0.5308\n"
     ]
    }
   ],
   "source": [
    "history = autoIntMLP_model.fit(train_df[u_i_feature + meta_features], train_df[label], epochs=epochs, batch_size=batch_size, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1027388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6035/6035 [00:00<00:00, 35839.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# 사용자에게 예측된 정보를 저장하는 딕셔너리 \n",
    "user_pred_info = {}\n",
    "# top10개\n",
    "top = 10\n",
    "# 테스트 값을 가지고 옵니다. \n",
    "mymodel_user_pred_info = test_model(autoIntMLP_model, test_df)\n",
    "# 사용자마다 돌면서 예측 데이터 중 가장 높은 top 10만 가져옵니다. \n",
    "for user, data_info in tqdm(mymodel_user_pred_info.items(), total=len(mymodel_user_pred_info), position=0, leave=True):\n",
    "    ranklist = sorted(data_info, key=lambda s : s[1], reverse=True)[:top]\n",
    "    ranklist = list(dict.fromkeys([r[0] for r in ranklist]))\n",
    "    user_pred_info[str(user)] = ranklist\n",
    "# 원본 테스트 데이터에서 label이 1인 사용자 별 영화 정보를 가져옵니다.\n",
    "test_data = test_df[test_df['label']==1].groupby('user_id')['movie_id'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4369b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 305/5994 [00:00<00:01, 3036.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5994/5994 [00:01<00:00, 4208.73it/s]\n",
      "100%|██████████| 5994/5994 [00:00<00:00, 51508.03it/s]\n"
     ]
    }
   ],
   "source": [
    "mymodel_ndcg_result = {}\n",
    "mymodel_hitrate_result = {}\n",
    "\n",
    "# 모델 예측값과 원본 테스트 데이터를 비교해서 어느정도 성능이 나왔는지 NDCG와 Hitrate를 비교합니다.\n",
    "\n",
    "# NDCG\n",
    "for user, data_info in tqdm(test_data.items(), total=len(test_data), position=0, leave=True):\n",
    "    mymodel_pred = user_pred_info.get(str(user))\n",
    "\n",
    "    testset = list(set(np.array(data_info).astype(int)))\n",
    "    mymodel_pred = mymodel_pred[:top]\n",
    "\n",
    "    # NDCG 값 구하기\n",
    "    user_ndcg = get_NDCG(mymodel_pred, testset)\n",
    "\n",
    "    mymodel_ndcg_result[user] = user_ndcg\n",
    "\n",
    "# Hitrate\n",
    "for user, data_info in tqdm(test_data.items(), total=len(test_data), position=0, leave=True):\n",
    "    mymodel_pred = user_pred_info.get(str(user))\n",
    "\n",
    "    testset = list(set(np.array(data_info).astype(int)))\n",
    "    mymodel_pred = mymodel_pred[:top]\n",
    "\n",
    "    # hitrate 값 구하기\n",
    "    user_hitrate = get_hit_rate(mymodel_pred, testset)\n",
    "\n",
    "    # 사용자 hitrate 결과 저장\n",
    "    mymodel_hitrate_result[user] = user_hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62b63a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mymodel ndcg :  0.6777\n",
      " mymodel hitrate :  0.64179\n"
     ]
    }
   ],
   "source": [
    "print(\" mymodel ndcg : \", round(np.mean(list(mymodel_ndcg_result.values())), 5))\n",
    "print(\" mymodel hitrate : \", round(np.mean(list(mymodel_hitrate_result.values())), 5))\n",
    "\n",
    "#  mymodel ndcg :  0.66298\n",
    "#  mymodel hitrate :  0.6331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2a23b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 새 가중치 저장 성공: C:\\Users\\Admin\\autoint\\model\\autoIntMLP1_model_weights.weights.h5\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# # 1. 'model' 폴더가 현재 경로에 있는지 확인하고 없으면 만듭니다.\n",
    "# model_dir = './model'\n",
    "# if not os.path.exists(model_dir):\n",
    "#     os.makedirs(model_dir)\n",
    "#     print(f\"✅ '{model_dir}' 폴더를 새로 생성했습니다.\")\n",
    "\n",
    "# # 2. 이제 다시 저장 코드를 실행합니다.\n",
    "# autoIntMLP_model.save_weights('./model/autoIntMLP_model_weights.weights.h5')\n",
    "# print(\"✅ 가중치 저장 완료!\")\n",
    "\n",
    "# # 1. 'model' 폴더가 현재 경로에 있는지 확인하고 없으면 만듭니다.\n",
    "# model_dir = './model'\n",
    "# if not os.path.exists(model_dir):\n",
    "#     os.makedirs(model_dir)\n",
    "#     print(f\"✅ '{model_dir}' 폴더를 새로 생성했습니다.\")\n",
    "\n",
    "# # 2. 이제 다시 저장 코드를 실행합니다.\n",
    "# autoIntMLP_model.save_weights('./model/autoIntMLP_model_weights.weights.h5')\n",
    "# print(\"✅ 가중치 저장 완료!\")\n",
    "\n",
    "import os\n",
    "save_path = r'C:\\Users\\Admin\\autoint\\model\\autoIntMLP1_model_weights.weights.h5'\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "autoIntMLP_model.save_weights(save_path)\n",
    "print(f\"✅ 새 가중치 저장 성공: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97d9f8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/label_encoders1.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "# 모델 객체를 pickled binary file 형태로 저장\n",
    "joblib.dump(label_encoders, './model/label_encoders1.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds6_rcmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
