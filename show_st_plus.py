# import streamlit as st
# import pandas as pd
# import numpy as np
# import tensorflow as tf
# import os
# import joblib
# from autointmlp import AutoIntMLPModel, predict_model
# from tensorflow.keras.models import load_model

# # ---------------------------
# # í˜ì´ì§€ ì„¤ì •
# # ---------------------------
# st.set_page_config(
#     page_title="ğŸ¬ ì˜í™” ì¶”ì²œ ì‹œìŠ¤í…œ",
#     page_icon="ğŸ¥",
#     layout="centered",
# )

# # ---------------------------
# # ì»¤ìŠ¤í…€ ìŠ¤íƒ€ì¼ ì ìš©
# # ---------------------------
# st.markdown(
#     """
#     <style>
#     /* ë°°ê²½ ìƒ‰ìƒ */
#     .stApp {
#         background-color: #fff9e6;  /* ì—°ë…¸ë€ìƒ‰ */
#     }
#     /* ì œëª© í°íŠ¸ í¬ê¸° */
#     h1 {
#         font-size: 36px;
#     }
#     h2 {
#         font-size: 28px;
#     }
#     /* ì¶”ì²œ ê²°ê³¼ í‘œ ìŠ¤íƒ€ì¼ */
#     .dataframe th {
#         background-color: #ffe680;
#         color: #000000;
#     }
#     </style>
#     """,
#     unsafe_allow_html=True
# )

# # ---------------------------
# # ë°ì´í„° ë¡œë“œ
# # ---------------------------
# @st.cache_resource
# def load_data():
#     project_path = os.path.abspath(os.getcwd())
#     data_dir_nm = 'data'
#     movielens_dir_nm = 'ml-1m'
#     model_dir_nm = 'model'
#     data_path = f"{project_path}/{data_dir_nm}"
#     model_path = f"{project_path}/{model_dir_nm}"
#     field_dims = np.load(f'{data_path}/field_dims.npy')
#     dropout= 0.4
#     embed_dim= 16
    
#     ratings_df = pd.read_csv(f'{data_path}/{movielens_dir_nm}/ratings_prepro.csv')
#     movies_df = pd.read_csv(f'{data_path}/{movielens_dir_nm}/movies_prepro.csv')
#     user_df = pd.read_csv(f'{data_path}/{movielens_dir_nm}/users_prepro.csv')

#     model = AutoIntMLPModel(
#         field_dims, embed_dim, att_layer_num=3, att_head_num=2, att_res=True,
#         dnn_hidden_units=(32, 32), dnn_activation='relu',
#         l2_reg_dnn=0, l2_reg_embedding=1e-5, dnn_use_bn=False, dnn_dropout=dropout, init_std=0.0001
#     )
    
#     # ëª¨ë¸ ì´ˆê¸°í™”
#     model(tf.constant([[0] * len(field_dims)], dtype=tf.int64))
#     model.load_weights(f'{model_path}/autoIntMLP_model_weights.weights.h5') 
#     label_encoders = joblib.load(f'{data_path}/label_encoders.pkl')
    
#     return user_df, movies_df, ratings_df, model, label_encoders

# # ---------------------------
# # ì‚¬ìš©ì-ì˜í™” ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
# # ---------------------------
# def get_user_seen_movies(ratings_df):
#     user_seen_movies = ratings_df.groupby('user_id')['movie_id'].apply(list).reset_index()
#     return user_seen_movies

# def get_user_non_seed_dict(movies_df, user_df, user_seen_movies):
#     unique_movies = movies_df['movie_id'].unique()
#     unique_users = user_df['user_id'].unique()
#     user_non_seen_dict = dict()

#     for user in unique_users:
#         user_seen_movie_list = user_seen_movies[user_seen_movies['user_id'] == user]['movie_id'].values[0]
#         user_non_seen_movie_list = list(set(unique_movies) - set(user_seen_movie_list))
#         user_non_seen_dict[user] = user_non_seen_movie_list
        
#     return user_non_seen_dict

# def get_user_info(user_id):
#     return users_df[users_df['user_id'] == user_id]

# def get_user_past_interactions(user_id):
#     return ratings_df[(ratings_df['user_id'] == user_id) & (ratings_df['rating'] >= 4)].merge(movies_df, on='movie_id')

# def get_recom(user, user_non_seen_dict, user_df, movies_df, r_year, r_month, model, label_encoders):
#     user_non_seen_movie = user_non_seen_dict.get(user)
#     user_id_list = [user for _ in range(len(user_non_seen_movie))]
#     r_decade = str(r_year - (r_year % 10)) + 's'
    
#     user_non_seen_movie = pd.merge(pd.DataFrame({'movie_id':user_non_seen_movie}), movies_df, on='movie_id')
#     user_info = pd.merge(pd.DataFrame({'user_id':user_id_list}), user_df, on='user_id')
#     user_info['rating_year'] = r_year
#     user_info['rating_month'] = r_month
#     user_info['rating_decade'] = r_decade
    
#     merge_data = pd.concat([user_non_seen_movie, user_info], axis=1)
#     merge_data.fillna('no', inplace=True)
#     merge_data = merge_data[['user_id', 'movie_id','movie_decade', 'movie_year', 'rating_year', 'rating_month', 'rating_decade', 
#                              'genre1','genre2', 'genre3', 'gender', 'age', 'occupation', 'zip']]
    
#     for col, le in label_encoders.items():
#         merge_data[col] = le.fit_transform(merge_data[col])
    
#     recom_top = predict_model(model, merge_data)
#     recom_top = [r[0] for r in recom_top]
#     origin_m_id = label_encoders['movie_id'].inverse_transform(recom_top)
    
#     return movies_df[movies_df['movie_id'].isin(origin_m_id)]

# # ---------------------------
# # ë°ì´í„° ì¤€ë¹„
# # ---------------------------
# users_df, movies_df, ratings_df, model, label_encoders = load_data()
# user_seen_movies = get_user_seen_movies(ratings_df)
# user_non_seen_dict = get_user_non_seed_dict(movies_df, users_df, user_seen_movies)

# # ---------------------------
# # ìƒë‹¨ íƒ€ì´í‹€
# # ---------------------------
# st.markdown("## ğŸ¬ ì˜í™” ì¶”ì²œ ê²°ê³¼ ì‚´í´ë³´ê¸° ğŸ¬", unsafe_allow_html=True)

# # ---------------------------
# # ì…ë ¥ì°½
# # ---------------------------
# st.header("ì‚¬ìš©ì ì •ë³´ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
# user_id = st.number_input("ğŸ‘¤ ì‚¬ìš©ì ID ì…ë ¥", 
#                           min_value=users_df['user_id'].min(), 
#                           max_value=users_df['user_id'].max(), 
#                           value=users_df['user_id'].min())

# r_year = st.number_input("ğŸ“… ì¶”ì²œ íƒ€ê²Ÿ ì—°ë„ ì…ë ¥", 
#                          min_value=ratings_df['rating_year'].min(), 
#                          max_value=ratings_df['rating_year'].max(), 
#                          value=ratings_df['rating_year'].min())

# r_month = st.number_input("ğŸ—“ ì¶”ì²œ íƒ€ê²Ÿ ì›” ì…ë ¥", 
#                           min_value=ratings_df['rating_month'].min(), 
#                           max_value=ratings_df['rating_month'].max(), 
#                           value=ratings_df['rating_month'].min())

# # ---------------------------
# # ì¶”ì²œ ê²°ê³¼ ë²„íŠ¼
# # ---------------------------
# if st.button("ğŸ¿ ì¶”ì²œ ê²°ê³¼ ë³´ê¸°"):
#     st.subheader("ì‚¬ìš©ì ê¸°ë³¸ ì •ë³´")
#     user_info = get_user_info(user_id)
#     st.dataframe(user_info)

#     st.subheader("ì‚¬ìš©ìê°€ ê³¼ê±°ì— ë´¤ë˜ ì˜í™” (í‰ì  4ì  ì´ìƒ)")
#     user_interactions = get_user_past_interactions(user_id)
#     st.dataframe(user_interactions)

#     st.subheader("ì¶”ì²œ ê²°ê³¼ ğŸ¯")
#     recommendations = get_recom(user_id, user_non_seen_dict, users_df, movies_df, r_year, r_month, model, label_encoders)
#     st.dataframe(recommendations)

# íŠœë‹ í›„ ì½”ë“œ
import streamlit as st
import pandas as pd
import numpy as np
import tensorflow as tf
import os
import joblib
from autointmlp import AutoIntMLPModel, predict_model

# ---------------------------
# í˜ì´ì§€ ì„¤ì •
# ---------------------------
st.set_page_config(
    page_title="ë½€ì§ ì˜í™” ì¶”ì²œ ì‹œìŠ¤í…œ",
    page_icon="ğŸ¿",
    layout="centered",
)

# ---------------------------
# ê·€ì—¼ë½€ì§ ì»¤ìŠ¤í…€ ìŠ¤íƒ€ì¼ ì ìš©
# ---------------------------
st.markdown(
    """
    <style>
    .stApp { background-color: #FFFDF5; }
    
    /* ì „ê´‘íŒ íš¨ê³¼ */
    .marquee {
        background-color: #FF4B4B;
        color: white;
        padding: 10px;
        font-weight: bold;
        border-radius: 15px;
        text-align: center;
        margin-bottom: 25px;
        font-size: 20px;
        box-shadow: 0px 4px 10px rgba(0,0,0,0.1);
    }

    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    div.stButton > button {
        background-color: #FF4B4B;
        color: white;
        border-radius: 20px;
        border: none;
        padding: 10px 24px;
        font-size: 18px;
        font-weight: bold;
        transition: 0.3s;
        width: 100%;
    }
    div.stButton > button:hover {
        background-color: #FFD700;
        color: #FF4B4B;
        transform: scale(1.02);
    }

    /* íƒ­ ìŠ¤íƒ€ì¼ */
    .stTabs [data-baseweb="tab-list"] { gap: 10px; }
    .stTabs [data-baseweb="tab"] {
        background-color: #f0f2f6;
        border-radius: 10px 10px 0px 0px;
        padding: 10px 20px;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ---------------------------
# ë°ì´í„° ë° ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
# ---------------------------
@st.cache_resource
def load_data():
    project_path = r"C:\Users\Admin\autoint"
    data_path = os.path.join(project_path, 'data')
    weights_path = r"C:\Users\Admin\autoint\model\autoIntMLP1_model_weights.weights.h5"
    encoder_path = r"C:\Users\Admin\autoint\model\label_encoders1.pkl"
    
    field_dims = np.load(os.path.join(data_path, 'field_dims.npy'))
    embed_dim = 32
    
    model = AutoIntMLPModel(
        field_dims=field_dims,
        embedding_size=embed_dim,
        att_layer_num=3,
        att_head_num=4,
        att_res=True,
        dnn_hidden_units=(256, 128, 64),
        dnn_activation='relu',
        dnn_use_bn=True,
        dnn_dropout=0.2
    )
    
    # ëª¨ë¸ ë¹Œë“œ (ë”ë¯¸ ë°ì´í„°)
    model(tf.constant([[0] * len(field_dims)], dtype=tf.int64))
    
    load_status = True
    error_msg = ""
    try:
        model.load_weights(weights_path)
    except Exception as e:
        load_status = False
        error_msg = str(e)
    
    ratings_df = pd.read_csv(os.path.join(data_path, 'ml-1m', 'ratings_prepro.csv'))
    movies_df = pd.read_csv(os.path.join(data_path, 'ml-1m', 'movies_prepro.csv'))
    user_df = pd.read_csv(os.path.join(data_path, 'ml-1m', 'users_prepro.csv'))
    label_encoders = joblib.load(encoder_path)
    
    return user_df, movies_df, ratings_df, model, label_encoders, load_status, error_msg

# ---------------------------
# ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ---------------------------
def get_user_seen_movies(ratings_df):
    return ratings_df.groupby('user_id')['movie_id'].apply(list).reset_index()

def get_user_non_seed_dict(movies_df, user_df, user_seen_movies):
    unique_movies = movies_df['movie_id'].unique()
    unique_users = user_df['user_id'].unique()
    user_non_seen_dict = {}
    for user in unique_users:
        seen_list = user_seen_movies[user_seen_movies['user_id'] == user]['movie_id'].values
        user_seen_movie_list = seen_list[0] if len(seen_list) > 0 else []
        user_non_seen_dict[user] = list(set(unique_movies) - set(user_seen_movie_list))
    return user_non_seen_dict

def get_recom(user, user_non_seen_dict, user_df, movies_df, r_year, r_month, model, label_encoders):
    # 1. ì•ˆ ë³¸ ì˜í™” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    user_non_seen_movie_ids = user_non_seen_dict.get(user, [])
    if not user_non_seen_movie_ids:
        return pd.DataFrame()

    # 2. ì¶”ì²œ ì‹œì  ì •ë³´ ì„¤ì •
    r_decade = str(r_year - (r_year % 10)) + 's'
    user_info = user_df[user_df['user_id'] == user].iloc[0]
    
    # 3. ì˜ˆì¸¡ìš© ë°ì´í„°í”„ë ˆì„ ìƒì„± (í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•œ êµ¬ì¡°)
    # movies_dfì— movie_idê°€ ë¬¸ìì—´ì¸ì§€ ìˆ«ìì—´ì¸ì§€ ë§ì¶°ì£¼ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
    merge_data = movies_df[movies_df['movie_id'].isin(user_non_seen_movie_ids)].copy()
    
    # ì‚¬ìš©ì ë° ì‹œê°„ í”¼ì²˜ ì£¼ì…
    merge_data['user_id'] = user
    merge_data['rating_year'] = r_year
    merge_data['rating_month'] = r_month
    merge_data['rating_decade'] = r_decade
    
    for col in ['gender', 'age', 'occupation', 'zip']:
        merge_data[col] = user_info[col]

    # 4. [ë§¤ìš° ì¤‘ìš”] í•™ìŠµ ì‹œ ì‚¬ìš©í–ˆë˜ 14ê°œ ì»¬ëŸ¼ ìˆœì„œ ë° ì´ë¦„ ì¼ì¹˜
    input_cols = [
        'user_id', 'movie_id', 'movie_decade', 'movie_year', 
        'rating_year', 'rating_month', 'rating_decade', 
        'genre1', 'genre2', 'genre3', 'gender', 'age', 'occupation', 'zip'
    ]
    
    # ë¶€ì¡±í•œ ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ 'no'ë¡œ ì±„ì›Œì£¼ê¸° (í•™ìŠµ ë°ì´í„°ì˜ ë¹ˆê°’ ì²˜ë¦¬ ë°©ì‹)
    for col in input_cols:
        if col not in merge_data.columns:
            merge_data[col] = 'no'

    # ìˆœì„œ ì¬ë°°ì¹˜
    merge_data = merge_data[input_cols]
    
    # 5. ì¸ì½”ë”© ì²˜ë¦¬ (í•™ìŠµ ì½”ë“œì˜ LabelEncoder í™œìš©)
    # ëª¨ë“  ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•œ ë’¤ ì¸ì½”ë”© (í•™ìŠµ ë•Œ strë¡œ ë¶ˆë €ê¸° ë•Œë¬¸)
    for col in input_cols:
        if col in label_encoders:
            le = label_encoders[col]
            merge_data[col] = merge_data[col].astype(str)
            # ì¸ì½”ë”ì— ì—†ëŠ” ê°’ ì²˜ë¦¬ (ì²« ë²ˆì§¸ í´ë˜ìŠ¤ë¡œ ëŒ€ì²´)
            known_classes = set(le.classes_)
            merge_data[col] = merge_data[col].apply(lambda x: x if x in known_classes else le.classes_[0])
            merge_data[col] = le.transform(merge_data[col])
    
    # 6. ì˜ˆì¸¡ ë° ê²°ê³¼ ë„ì¶œ
    try:
        # ëª¨ë¸ ì…ë ¥ ì‹œ ì •ìˆ˜í˜• í…ì„œë¡œ ë³€í™˜
        preds = model.predict(merge_data.values.astype(np.int64), verbose=0)
        
        # ì˜ˆì¸¡ê°’ê³¼ ì˜í™” ID ê²°í•© í›„ ìƒìœ„ 10ê°œ ì¶”ì¶œ
        merge_data['pred_prob'] = preds
        top_10 = merge_data.sort_values(by='pred_prob', ascending=False).head(10)
        
        # ì¸ì½”ë”©ëœ movie_idë¥¼ ë‹¤ì‹œ ì›ë˜ IDë¡œ ë³µì› (inverse_transform)
        # ì´ë¯¸ merge_dataì— ì›ë˜ ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë¯€ë¡œ index ê¸°ë°˜ìœ¼ë¡œ ì°¾ê±°ë‚˜ ì›ë³¸ join
        recom_movie_indices = top_10['movie_id'].values
        # ë§Œì•½ movie_idê°€ ì´ë¯¸ ì¸ì½”ë”©ëœ ìƒíƒœë¼ë©´ ì•„ë˜ ì¤„ ì‚¬ìš©
        origin_m_ids = label_encoders['movie_id'].inverse_transform(recom_movie_indices)
        
        return movies_df[movies_df['movie_id'].astype(str).isin(origin_m_ids.astype(str))]
    except Exception as e:
        st.error(f"âš ï¸ ì˜ˆì¸¡ ë„ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()
    
# ---------------------------
# ë©”ì¸ UI ì‹¤í–‰
# ---------------------------
users_df, movies_df, ratings_df, model, label_encoders, load_ok, err_text = load_data()
user_seen_movies = get_user_seen_movies(ratings_df)
user_non_seen_dict = get_user_non_seed_dict(movies_df, users_df, user_seen_movies)

# --- ìƒë‹¨ ë ˆì´ì•„ì›ƒ ---
st.markdown('<div class="marquee">âœ¨ WELCOME TO THE BEST CINEMA âœ¨</div>', unsafe_allow_html=True)

col_t1, col_t2 = st.columns([1, 4])
with col_t1:
    st.image("https://cdn-icons-png.flaticon.com/512/3163/3163478.png", width=100)
with col_t2:
    st.title("ì˜¤ëŠ˜ì€ ì–´ë–¤ ì˜í™”ë¥¼ ë³¼ê¹Œìš”?")
    st.write("ë‹¹ì‹ ì˜ ì·¨í–¥ì„ íƒ•íƒ•! ì €ê²©í•  ì˜í™”ë¥¼ ì°¾ì•„ë“œë ¤ìš” ğŸ”«ğŸ¿")

st.divider()

# --- ì…ë ¥ êµ¬ì—­ ---
st.subheader("ğŸ“ í‹°ì¼“ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
c1, c2, c3 = st.columns(3)
with c1:
    user_id = st.number_input("ğŸ‘¤ ì‚¬ìš©ì ID", min_value=int(users_df['user_id'].min()), max_value=int(users_df['user_id'].max()))
with c2:
    r_year = st.number_input("ğŸ“… ì¶”ì²œ ì—°ë„", min_value=2000, max_value=2025, value=2000)
with c3:
    r_month = st.number_input("ğŸ—“ ì¶”ì²œ ì›”", min_value=1, max_value=12, value=1)

st.write("")

# --- ì¶”ì²œ ì‹¤í–‰ ---
if st.button("ğŸ“½ï¸ ì˜í™”ì„ ì¶”ì²œí•´ ë“œë¦´ê²Œìš”!"):
    st.balloons()
    
    tab1, tab2 = st.tabs(["ğŸ‘¤ ì‚¬ìš©ì í”„ë¡œí•„", "ğŸ¯ ì¶”ì²œ ê²°ê³¼"])
    
    with tab1:
        col_left, col_right = st.columns(2)
        with col_left:
            st.markdown("##### **ë‚´ ê¸°ë³¸ ì •ë³´**")
            st.dataframe(users_df[users_df['user_id'] == user_id], use_container_width=True)
        with col_right:
            st.markdown("##### **ë‚´ê°€ ì¢‹ì•„í•œ ì˜í™”**")
            past_m = ratings_df[(ratings_df['user_id'] == user_id) & (ratings_df['rating'] >= 4)].merge(movies_df, on='movie_id')
            d_cols = ['title']
            if 'genre1' in past_m.columns: d_cols.append('genre1')
            st.dataframe(past_m[d_cols].head(5), use_container_width=True)

    with tab2:
        st.markdown("##### **ğŸ¬ ë‹¹ì‹ ì„ ìœ„í•œ ì˜¤ëŠ˜ì˜ ì¶”ì²œ TOP 10**")
        with st.spinner('ì˜ì‚¬ê¸°ë¥¼ ëŒë¦¬ëŠ” ì¤‘... ğŸï¸'):
            recommendations = get_recom(user_id, user_non_seen_dict, users_df, movies_df, r_year, r_month, model, label_encoders)
            if not recommendations.empty:
                r_cols = ['title']
                if 'genre1' in recommendations.columns: r_cols.append('genre1')
                st.table(recommendations[r_cols].reset_index(drop=True))
                st.success("ë§›ìˆê²Œ ê´€ëŒí•˜ì„¸ìš”! ğŸ¿ğŸ¥¤")
            else:
                st.warning("ì¶”ì²œ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ ğŸ˜¢")

# --- í•˜ë‹¨ ì •ë³´ (ì„±ê³µ ë©”ì‹œì§€ ì´ë™) ---
st.write("")
st.write("")
st.divider()
if load_ok:
    st.caption("âœ… ì‹œìŠ¤í…œ ìƒíƒœ: ëª¨ë¸ ê°€ì¤‘ì¹˜ ë° ë°ì´í„° ë¡œë“œ ì„±ê³µ")
else:
    st.error(f"âŒ ì‹œìŠ¤í…œ ìƒíƒœ: ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨ ({err_text})")
st.caption("âœ¨ Movie Recommendation System | AutoInt + MLP Architecture âœ¨")